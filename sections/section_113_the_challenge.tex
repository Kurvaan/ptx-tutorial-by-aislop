\subsubsection{The Challenge}

Quantized models use lower-precision representations (e.g., INT8 or INT4) to reduce memory usage and increase throughput. However, naive quantization often leads to accuracy loss, and standard libraries may not support all quantization schemes.

